{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsoham7/DL/blob/main/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs2cKPUiGMHv",
        "outputId": "18571954-b447-44df-ede4-d377e80b9f21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=8ab19af5fd19152fb609b7b3d1b57fd09727284daa0fb786e2aaa9229a61cea9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "_K1oeT3gIW_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark.rdd import RDD\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql import DataFrame\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SQLContext\n",
        "from pyspark.sql import functions\n",
        "from pyspark.sql.functions import lit, desc, col, size, array_contains\\\n",
        ", isnan, udf, hour, array_min, array_max, countDistinct\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql.functions import mean, col, split, col, regexp_extract, when, lit"
      ],
      "metadata": {
        "id": "A8tgPMuNIt4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2:Upload purchases.csv to use as sample data."
      ],
      "metadata": {
        "id": "gMUgqavkKJ7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kbAd5p4EKTVx",
        "outputId": "be92eb04-cbfc-4b36-e293-81efc7d00ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-86108ef7-c5fe-4085-b5fe-4ed6fabcfae3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-86108ef7-c5fe-4085-b5fe-4ed6fabcfae3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Purchase - Purchase.csv to Purchase - Purchase.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Create a spark container by calling SparkSession."
      ],
      "metadata": {
        "id": "1CbJKD57K5RL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Create session in order to be capable of accessing all Spark API\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .appName(\"Purchase\") \\\n",
        "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "    .getOrCreate()\n"
      ],
      "metadata": {
        "id": "zz8am002K6fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define data schema file we want to read\n",
        "purchaseSchema = StructType([\n",
        "    StructField(\"Date\", DateType(), True),\n",
        "    StructField(\"Time\", StringType(), True),\n",
        "    StructField(\"City\", StringType(), True),\n",
        "    StructField(\"Item\", StringType(), True),\n",
        "    StructField(\"Total\", FloatType(), True),\n",
        "    StructField(\"Payment\", StringType(), True),\n",
        "])"
      ],
      "metadata": {
        "id": "q-avDirCLlIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"Purchase\").getOrCreate()\n",
        "\n",
        "# Define schema\n",
        "purchaseSchema = StructType([\n",
        "    StructField(\"Date\", StringType(), True),\n",
        "    StructField(\"Time\", StringType(), True),\n",
        "    StructField(\"City\", StringType(), True),\n",
        "    StructField(\"Item\", StringType(), True),\n",
        "    StructField(\"Total\", IntegerType(), True),\n",
        "    StructField(\"Payment\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Read the CSV file with defined schema and show 3 rows\n",
        "purchaseDataframe = spark.read.csv(\n",
        "    \"/content/Purchase - Purchase.csv\",  # Adjusted file path to point to the correct location\n",
        "    header=True,\n",
        "    schema=purchaseSchema,\n",
        "    sep=\",\"  # Use a comma as the delimiter, since it's not tab-delimited\n",
        ")\n",
        "\n",
        "# Show 3 rows of the DataFrame\n",
        "purchaseDataframe.show(3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO7NCO8UO_3j",
        "outputId": "d99c5a62-3796-4370-d0a5-bc67f9a97479"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----------+----------------+-----+-------+\n",
            "|      Date|Time|      City|            Item|Total|Payment|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "|2012-01-01|9:00|  San Jose|  Men's Clothing| NULL|   Amex|\n",
            "|2012-01-01|9:00|Fort Worth|Women's Clothing| NULL|   Visa|\n",
            "|2012-01-01|9:00| San Diego|           Music| NULL|   Cash|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Count Number of Rows of our DataFrame."
      ],
      "metadata": {
        "id": "vVU1W8hyL9Ev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count number of rows of our dataFrame\n",
        "num_rows = purchaseDataframe.count()\n",
        "print(\"number of rows: \", num_rows)"
      ],
      "metadata": {
        "id": "J-qEB1alL6qV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec281a3a-5b72-4a02-9a54-a6938a017c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of rows:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Show our DataFrame schema\n"
      ],
      "metadata": {
        "id": "FH0CVcoEQbrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#show our dataFrame schema\n",
        "purchaseDataframe.printSchema()"
      ],
      "metadata": {
        "id": "-IQDimWoQe_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0f470e9-13fe-4a8a-edf0-15eee9ccc641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Time: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Item: string (nullable = true)\n",
            " |-- Total: integer (nullable = true)\n",
            " |-- Payment: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Show statistics of the data we want."
      ],
      "metadata": {
        "id": "pY3AF2QLMXga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#show statistic of the data we wanta\n",
        "purchaseDataframe.describe('Total').show()"
      ],
      "metadata": {
        "id": "dpkQjMD9QnJk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc36a01-c7de-43e4-d1da-2bd975e6449e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+\n",
            "|summary|Total|\n",
            "+-------+-----+\n",
            "|  count|    0|\n",
            "|   mean| NULL|\n",
            "| stddev| NULL|\n",
            "|    min| NULL|\n",
            "|    max| NULL|\n",
            "+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Creating a new dataFrame from a subset of existing dataFrame."
      ],
      "metadata": {
        "id": "EG1qyO7XQxTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchaseDataframe.select('City').distinct().count()"
      ],
      "metadata": {
        "id": "DVECI7k6Qx9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be414e11-e648-4805-bb6a-d786f6e5d33e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 9: Create new DataFrame from \"City\" and \"Total\" columns."
      ],
      "metadata": {
        "id": "zNR-7woSQ5Ej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create new dataFrame from \"City\" and \"Total\" columns\n",
        "newDataframe = purchaseDataframe.select(purchaseDataframe['City'],\n",
        "                                        purchaseDataframe['Total'])\n",
        "\n",
        "# top 10 rows\n",
        "newDataframe.show(3)\n",
        "print('=================================')\n",
        "# schema of dataframe\n",
        "newDataframe.printSchema()"
      ],
      "metadata": {
        "id": "FpU0ogm5Q6fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0f633c-bc9a-4f79-abd4-1576f7b65aa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|      City|Total|\n",
            "+----------+-----+\n",
            "|  San Jose| NULL|\n",
            "|Fort Worth| NULL|\n",
            "| San Diego| NULL|\n",
            "+----------+-----+\n",
            "\n",
            "=================================\n",
            "root\n",
            " |-- City: string (nullable = true)\n",
            " |-- Total: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter only row data whose \"Total\" column value > 300"
      ],
      "metadata": {
        "id": "i3CTy4YUSFrv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filter only row data whose \"Total\" column value > 300\n",
        "purchaseDataframe.filter(purchaseDataframe['Total'] > 300).show(5)"
      ],
      "metadata": {
        "id": "_XNISUvlSGN-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be57436-2873-4ead-d163-e6597190bb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+----+-----+-------+\n",
            "|Date|Time|City|Item|Total|Payment|\n",
            "+----+----+----+----+-----+-------+\n",
            "+----+----+----+----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 10: Pyspark Sorting DataFrame by City column"
      ],
      "metadata": {
        "id": "SuIwWz4KSQ8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sorting dataframe by city\n",
        "sortedByCity = purchaseDataframe.orderBy('City').show(3)"
      ],
      "metadata": {
        "id": "Pb4dCY5wSSnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a6a057-66c4-48a7-aa94-8c0c770fff77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----------+----------------+-----+-------+\n",
            "|      Date|Time|      City|            Item|Total|Payment|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "|2012-01-01|9:00|Fort Worth|Women's Clothing| NULL|   Visa|\n",
            "|2012-01-01|9:00| San Diego|           Music| NULL|   Cash|\n",
            "|2012-01-01|9:00|  San Jose|  Men's Clothing| NULL|   Amex|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 11: Calculating number of transactions in each city."
      ],
      "metadata": {
        "id": "Sum736JsShPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numTransactionEachCity = purchaseDataframe.groupBy(\"City\").count()\n",
        "numTransactionEachCity.show(3)"
      ],
      "metadata": {
        "id": "xIVnFB3GSh0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062aa32e-d7e6-4efa-d553-717642afd62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|      City|count|\n",
            "+----------+-----+\n",
            "| San Diego|    1|\n",
            "|  San Jose|    1|\n",
            "|Fort Worth|    1|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 12: Since Spark dataFrame is distributed into clusters, we cannot access it by\n",
        "[row,column] as we can do in pandas dataFrame for example. There is an alternative way\n",
        "to do that in Pyspark by creating a new column \"index\". Then, we can use the \".filter()\"\n",
        "function on our \"index\" column.\n",
        "Then,"
      ],
      "metadata": {
        "id": "dmR0ZZpmS_AE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import monotonically_increasing_id\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "\n",
        "newPurchasedDataframe = purchaseDataframe.withColumn(\n",
        "    \"index\", monotonically_increasing_id())\n",
        "newPurchasedDataframe.show(10)\n",
        "\n",
        "row2Till4 = newPurchasedDataframe.filter((newPurchasedDataframe['index']>=2) &\n",
        "                                        (newPurchasedDataframe['index']<=4))\n",
        "# The line below had an extra indent. I've removed it to align with the previous line.\n",
        "row2Till4.show()"
      ],
      "metadata": {
        "id": "4FLcBwt9S_v8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b9d838-1fd0-4e7c-dcda-1c10e18d1931"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----------+----------------+-----+-------+-----+\n",
            "|      Date|Time|      City|            Item|Total|Payment|index|\n",
            "+----------+----+----------+----------------+-----+-------+-----+\n",
            "|2012-01-01|9:00|  San Jose|  Men's Clothing| NULL|   Amex|    0|\n",
            "|2012-01-01|9:00|Fort Worth|Women's Clothing| NULL|   Visa|    1|\n",
            "|2012-01-01|9:00| San Diego|           Music| NULL|   Cash|    2|\n",
            "+----------+----+----------+----------------+-----+-------+-----+\n",
            "\n",
            "+----------+----+---------+-----+-----+-------+-----+\n",
            "|      Date|Time|     City| Item|Total|Payment|index|\n",
            "+----------+----+---------+-----+-----+-------+-----+\n",
            "|2012-01-01|9:00|San Diego|Music| NULL|   Cash|    2|\n",
            "+----------+----+---------+-----+-----+-------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "F6w2EN2hTz4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#particular column value\n",
        "dataRow2ColumnTotal = newPurchasedDataframe.filter(newPurchasedDataframe['index']==2).select('Total')\n",
        "dataRow2ColumnTotal.show()"
      ],
      "metadata": {
        "id": "QGGB-gwmT2ow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b518eff-19fd-48e9-daff-f900d4718072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|Total|\n",
            "+-----+\n",
            "| NULL|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchaseDataframe.filter(purchaseDataframe.City.isNull()).show()"
      ],
      "metadata": {
        "id": "zLiCuLrmUMt-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce2fbfd0-425d-48c9-9357-ccccc4586320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+----+----+----+-----+-------+\n",
            "|Date|Time|City|Item|Total|Payment|\n",
            "+----+----+----+----+-----+-------+\n",
            "+----+----+----+----+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 13: Drop duplicate rows and count the number of duplicate rows in Pyspark"
      ],
      "metadata": {
        "id": "yUbrqKLsUmHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#count the number of original data rows\n",
        "n1 =purchaseDataframe.count()\n",
        "print(\"number of original data rows: \", n1)\n",
        "#count the number of data rows after deleting duplicated data\n",
        "n2 = purchaseDataframe.dropDuplicates().count()\n",
        "print(\"number of data rows after deleting duplicated data: \", n2)\n",
        "n3 = n1 - n2\n",
        "print(\"number of duplicate rows: \", n3)"
      ],
      "metadata": {
        "id": "Seg1DsbQUbgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9416da01-6e76-48f6-b603-4c20387bebf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of original data rows:  3\n",
            "number of data rows after deleting duplicated data:  3\n",
            "number of duplicate rows:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 14: Delete row if there is at least one (column) missing data."
      ],
      "metadata": {
        "id": "sHURdc8UU_5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PurchaseNoMissingValue = purchaseDataframe.dropDuplicates().dropna(\n",
        "how=\"any\")# use how=\"all\" for missing data in the entire column\n",
        "#The assignment should be aligned with the previous line\n",
        "numberOfMissingValueAny = n1 - PurchaseNoMissingValue.count()\n",
        "print(\"number of rows with missing data: \", numberOfMissingValueAny)"
      ],
      "metadata": {
        "id": "NGdn_iHJVA6R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "718e2b4f-173e-4227-e71a-6e930f956afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of rows with missing data:  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchaseDataframe.show(3)"
      ],
      "metadata": {
        "id": "lY3Sq5XxVYO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b576cbb2-1259-4fa6-eaa3-626470a69f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----+----------+----------------+-----+-------+\n",
            "|      Date|Time|      City|            Item|Total|Payment|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "|2012-01-01|9:00|  San Jose|  Men's Clothing| NULL|   Amex|\n",
            "|2012-01-01|9:00|Fort Worth|Women's Clothing| NULL|   Visa|\n",
            "|2012-01-01|9:00| San Diego|           Music| NULL|   Cash|\n",
            "+----------+----+----------+----------------+-----+-------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 15: Pyspark Calculate Column Mean"
      ],
      "metadata": {
        "id": "1JKm2a4tVdVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meanTotal = purchaseDataframe.groupBy().avg(\"Total\").take(1) [0][0]\n",
        "print('Mean total:',meanTotal)"
      ],
      "metadata": {
        "id": "KEplJVZmVf1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f525d86-9dac-44b0-d5cf-ff65c3b1c3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean total: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V97OwtxJG_55"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}